{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e286d982",
   "metadata": {
    "id": "D6U0AsVt0pPR"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import os\n",
    "import cv2 \n",
    "import keras.callbacks\n",
    "import numpy as np\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras import regularizers\n",
    "from keras.constraints import maxnorm \n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cea5d9",
   "metadata": {
    "id": "7zjt2ryb58uh"
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "img_list = []\n",
    "\n",
    "#Hàm dùng để cắt ảnh, lật ảnh, xoay ảnh\n",
    "def cropFace():\n",
    "    list_person = \"\"\n",
    "    root = 'CelebrityFacesDataset'\n",
    "    for index, person in enumerate(listdir(root)): \n",
    "        path_person = root + \"/\" + str(person)\n",
    "        print(\"{},\".format(person))\n",
    "        list_person += \"{},\".format(person) \n",
    "        for img in listdir(path_person):\n",
    "            path_img = path_person + \"/\" + str(img)\n",
    "            read_img = cv2.imread(path_img)\n",
    "\n",
    "            # Convert into grayscale\n",
    "            gray = cv2.cvtColor(read_img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "            # Load the cascade \n",
    "            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "            # Detect faces \n",
    "            faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "            if len(faces) > 0:\n",
    "                x, y, w, h = faces[-1]\n",
    "                cv2.rectangle(read_img, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "                faces = gray[y - 1:y + h + 1, x - 1:x + w + 1]\n",
    "                faces = cv2.resize(faces, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "                labels.append(index)\n",
    "                img_list.append(faces)\n",
    "\n",
    "                #flip img\n",
    "                labels.append(index)\n",
    "                img_list.append(cv2.flip(faces, 1))\n",
    "\n",
    "                #rotate img\n",
    "                labels.append(index)\n",
    "                img_list.append(cv2.rotate(faces, cv2.ROTATE_90_CLOCKWISE))\n",
    "\n",
    "    file_name_person = open('file_name_person.txt',\"w\")\n",
    "    file_name_person.write(list_person)\n",
    "\n",
    "\n",
    "def getImgList():\n",
    "    if len(img_list) <= 0:\n",
    "        cropFace()\n",
    "    return img_list, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af20eea5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xLt3F-0X58uh",
    "outputId": "7f492159-a890-45f6-aca1-ffeec809a38d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NganTran,\n",
      "Tom Hiddleston,\n",
      "PhanDinhVan,\n",
      "Robert Downey Jr,\n",
      "PhuTrong,\n",
      "Scarlett Johansson,\n",
      "TungDuong,\n",
      "Tom Cruise,\n",
      "NhanTran,\n",
      "MinhHuy,\n",
      "AnhTho,\n",
      "Chris Evans,\n",
      "Jennifer Lawrence,\n",
      "Mark Ruffalo,\n",
      "Benedict Cumberbatch,\n",
      "Chris Hemsworth,\n"
     ]
    }
   ],
   "source": [
    "# load and prepare data\n",
    "img_data_list, labels = getImgList() \n",
    "num_classes = len(set(labels))\n",
    "\n",
    "img_data = np.array(img_data_list, dtype='float32')\n",
    "\n",
    "labels = np.array(labels, dtype='int64')\n",
    "# scale down(so easy to work with)\n",
    "img_data /= 255.0\n",
    "img_data = np.expand_dims(img_data, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e44352",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-8FyuXxtLaKS",
    "outputId": "9096107d-ddcc-451f-990b-67552d854455"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# convert class labels to on-hot encoding\n",
    "Y = np_utils.to_categorical(labels, num_classes)\n",
    "\n",
    "# Shuffle the dataset\n",
    "x, y = shuffle(img_data, Y, random_state=2) \n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "\n",
    "# Defining the model\n",
    "input_shape = img_data[0].shape\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff157b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aO_rzp8a58ui",
    "outputId": "9277a8b6-f6fb-48b6-99a0-c8d07b8516d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 256, 256, 32)      320       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256, 256, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 128, 128, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 64)      18496     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 64, 64, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 262144)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               134218240 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                8208      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,245,264\n",
      "Trainable params: 134,245,264\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "70/70 [==============================] - 24s 187ms/step - loss: 5.6999 - accuracy: 0.2128 - val_loss: 5.0588 - val_accuracy: 0.4273\n",
      "Epoch 2/25\n",
      "70/70 [==============================] - 12s 169ms/step - loss: 4.8580 - accuracy: 0.4800 - val_loss: 4.6943 - val_accuracy: 0.5619\n",
      "Epoch 3/25\n",
      "70/70 [==============================] - 12s 167ms/step - loss: 4.3309 - accuracy: 0.5905 - val_loss: 4.1433 - val_accuracy: 0.6643\n",
      "Epoch 4/25\n",
      "70/70 [==============================] - 12s 167ms/step - loss: 3.7968 - accuracy: 0.7050 - val_loss: 3.8667 - val_accuracy: 0.6930\n",
      "Epoch 6/25\n",
      "70/70 [==============================] - 12s 166ms/step - loss: 3.6182 - accuracy: 0.7360 - val_loss: 3.6557 - val_accuracy: 0.7325\n",
      "Epoch 7/25\n",
      "70/70 [==============================] - 12s 167ms/step - loss: 3.3818 - accuracy: 0.7961 - val_loss: 3.6444 - val_accuracy: 0.7235\n",
      "Epoch 8/25\n",
      "70/70 [==============================] - 12s 166ms/step - loss: 3.2598 - accuracy: 0.8114 - val_loss: 3.3414 - val_accuracy: 0.7774\n",
      "Epoch 9/25\n",
      "70/70 [==============================] - 12s 167ms/step - loss: 3.1224 - accuracy: 0.8348 - val_loss: 3.3113 - val_accuracy: 0.7702\n",
      "Epoch 10/25\n",
      "70/70 [==============================] - 11s 163ms/step - loss: 3.1022 - accuracy: 0.8312 - val_loss: 3.3853 - val_accuracy: 0.7379\n",
      "Epoch 11/25\n",
      "70/70 [==============================] - 12s 166ms/step - loss: 2.9306 - accuracy: 0.8675 - val_loss: 3.1151 - val_accuracy: 0.7989\n",
      "Epoch 12/25\n",
      "70/70 [==============================] - 12s 167ms/step - loss: 2.8281 - accuracy: 0.8788 - val_loss: 3.0684 - val_accuracy: 0.7899\n",
      "Epoch 13/25\n",
      "70/70 [==============================] - 12s 166ms/step - loss: 2.6681 - accuracy: 0.9219 - val_loss: 3.0431 - val_accuracy: 0.7720\n",
      "Epoch 14/25\n",
      "70/70 [==============================] - 12s 166ms/step - loss: 2.5812 - accuracy: 0.9313 - val_loss: 2.9070 - val_accuracy: 0.8043\n",
      "Epoch 15/25\n",
      "70/70 [==============================] - 11s 164ms/step - loss: 2.4652 - accuracy: 0.9520 - val_loss: 2.9432 - val_accuracy: 0.7810\n",
      "Epoch 16/25\n",
      "70/70 [==============================] - 12s 166ms/step - loss: 2.4426 - accuracy: 0.9412 - val_loss: 2.8261 - val_accuracy: 0.7935\n",
      "Epoch 17/25\n",
      "70/70 [==============================] - 12s 167ms/step - loss: 2.3229 - accuracy: 0.9663 - val_loss: 2.7164 - val_accuracy: 0.8348\n",
      "Epoch 18/25\n",
      "70/70 [==============================] - 12s 166ms/step - loss: 2.2656 - accuracy: 0.9686 - val_loss: 2.6598 - val_accuracy: 0.8276\n",
      "Epoch 19/25\n",
      "70/70 [==============================] - 12s 167ms/step - loss: 2.1783 - accuracy: 0.9793 - val_loss: 2.6057 - val_accuracy: 0.8223\n",
      "Epoch 20/25\n",
      "70/70 [==============================] - 12s 166ms/step - loss: 2.1278 - accuracy: 0.9843 - val_loss: 2.5806 - val_accuracy: 0.8187\n",
      "Epoch 21/25\n",
      "70/70 [==============================] - 12s 167ms/step - loss: 2.0597 - accuracy: 0.9879 - val_loss: 2.5276 - val_accuracy: 0.8312\n",
      "Epoch 22/25\n",
      "70/70 [==============================] - 12s 166ms/step - loss: 2.0089 - accuracy: 0.9897 - val_loss: 2.4407 - val_accuracy: 0.8492\n",
      "Epoch 23/25\n",
      "70/70 [==============================] - 12s 168ms/step - loss: 1.9600 - accuracy: 0.9883 - val_loss: 2.4002 - val_accuracy: 0.8366\n",
      "Epoch 24/25\n",
      "70/70 [==============================] - 12s 166ms/step - loss: 1.9180 - accuracy: 0.9865 - val_loss: 2.3231 - val_accuracy: 0.8618\n",
      "Epoch 25/25\n",
      "70/70 [==============================] - 11s 163ms/step - loss: 1.8691 - accuracy: 0.9915 - val_loss: 2.3384 - val_accuracy: 0.8348\n",
      "Accuracy: 83.48%\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape, padding='same', activation='relu', kernel_constraint=maxnorm(2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(2),kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
    "    bias_regularizer=regularizers.L2(1e-4),\n",
    "    activity_regularizer=regularizers.L2(1e-5)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "epochs = 25\n",
    "lrate = 0.01\n",
    "decay = lrate / epochs \n",
    "sgd = SGD(learning_rate=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "# Fit the model\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32,\n",
    "          callbacks=callback)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
